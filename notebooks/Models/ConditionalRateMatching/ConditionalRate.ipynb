{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3f26690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sympy\n",
    "from dataclasses import dataclass\n",
    "from torchvision import transforms\n",
    "from torch.optim.adam import Adam\n",
    "from torch.distributions import Bernoulli\n",
    "from torch.distributions import Categorical\n",
    "from torch.nn.functional import softplus,softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0f2a81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:    \n",
    "    #data\n",
    "    number_of_spins:int = 3\n",
    "    number_of_states:int = 4\n",
    "    sample_size:int = 200\n",
    "    \n",
    "    dirichlet_alpha_0:float = 0.1\n",
    "    dirichlet_alpha_1:float = 100.\n",
    "    \n",
    "    bernoulli_probability_0:float = 0.2\n",
    "    bernoulli_probability_0:float = 0.8\n",
    "    \n",
    "    #process\n",
    "    gamma:float = .2 \n",
    "        \n",
    "    #model\n",
    "    \n",
    "    #temporal network\n",
    "    time_embed_dim:int = 9\n",
    "    hidden_dim:int = 50  \n",
    "        \n",
    "    #rate\n",
    "    \n",
    "    #training\n",
    "    number_of_epochs = 1\n",
    "    learning_rate = 0.01\n",
    "    batch_size:int = 5\n",
    "    device = \"cuda:0\"\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "7806e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.distributions import Dirichlet\n",
    "import torch\n",
    "\n",
    "def sample_categorical_from_dirichlet(probs,alpha=None,sample_size=100,dimension=3,number_of_states=2):\n",
    "    #ensure we have the probabilites \n",
    "    if probs is None:\n",
    "        if isinstance(alpha,float):\n",
    "            alpha = torch.full((number_of_states,),alpha)\n",
    "        else:\n",
    "            assert len(alpha.shape) == 1\n",
    "            assert alpha.size(0) == number_of_states\n",
    "        # Sample from the Dirichlet distribution\n",
    "        probs = torch.distributions.Dirichlet(alpha).sample([sample_size])\n",
    "    else:\n",
    "        assert probs.max() <= 10.\n",
    "        assert probs.max() >= 0.\n",
    "        \n",
    "    # Sample from the categorical distribution using the Dirichlet samples as probabilities\n",
    "    categorical_samples = torch.multinomial(probs, dimension, replacement=True)\n",
    "    return categorical_samples\n",
    "\n",
    "# Parameters\n",
    "dataset_0 = sample_categorical_from_dirichlet(probs=None,\n",
    "                                              alpha=config.dirichlet_alpha_0,\n",
    "                                              sample_size=config.sample_size,\n",
    "                                              dimension=config.number_of_spins,\n",
    "                                              number_of_states=config.number_of_states)\n",
    "tensordataset_0 = TensorDataset(dataset_0)\n",
    "dataloader_0 = DataLoader(tensordataset_0,batch_size=config.batch_size)\n",
    "\n",
    "dataset_1 = sample_categorical_from_dirichlet(probs=None,\n",
    "                                              alpha=config.dirichlet_alpha_1,\n",
    "                                              sample_size=183,\n",
    "                                              dimension=config.number_of_spins,\n",
    "                                              number_of_states=config.number_of_states)\n",
    "tensordataset_1 = TensorDataset(dataset_1)\n",
    "dataloader_1 = DataLoader(tensordataset_1,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bb541cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dataset_0 = len(tensordataset_0)\n",
    "size_dataset_1 = len(tensordataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "3ad25e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_integral(gamma,t1,t0):\n",
    "    \"\"\"\n",
    "    Dummy integral for constant rate\n",
    "    \"\"\"\n",
    "    interval = t1 - t0 \n",
    "    integral = gamma*interval\n",
    "    return integral\n",
    "\n",
    "def conditional_probability(config,x,x0,t,t0):\n",
    "    \"\"\"\n",
    "    \n",
    "    \\begin{equation}\n",
    "    P(x(t) = i|x(t_0)) = \\frac{1}{s} + w_{t,t_0}\\left(-\\frac{1}{s} + \\delta_{i,x(t_0)}\\right)\n",
    "    \\end{equation}\n",
    "\n",
    "    \\begin{equation}\n",
    "    w_{t,t_0} = e^{-S \\int_{t_0}^{t} \\beta(r)dr}\n",
    "    \\end{equation}\n",
    "\n",
    "    \"\"\"\n",
    "    right_shape = lambda x: x if len(x.shape) == 3 else x[:,:,None]\n",
    "    right_time_size = lambda t: t if isinstance(t,torch.Tensor) else torch.full((config.batch_size,),t)\n",
    "    \n",
    "    t1 = right_time_size(1.).to(x0.device)\n",
    "    t0 = right_time_size(0.).to(x0.device)\n",
    "    \n",
    "    S = config.number_of_states\n",
    "    integral_t0 = beta_integral(config.gamma,t,t0)\n",
    "    \n",
    "    w_t0  = torch.exp(-S*integral_t0)\n",
    "\n",
    "    x = right_shape(x)\n",
    "    x0 = right_shape(x0)\n",
    "\n",
    "    delta_x = (x == x0).float()\n",
    "    probability = 1./S + w_t0[:,None,None]*( (-1./S) + delta_x )\n",
    "    \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a22c0",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(x(t) = i|x(t_0)) = \\frac{1}{s} + w_{t,t_0}\\left(-\\frac{1}{s} + \\delta_{i,x(t_0)}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "w_{t,t_0} = e^{-S \\int_{t_0}^{t} \\beta(r)dr}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "0abee7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_transition_probability(config,x,x1,x0,t):\n",
    "    \"\"\"\n",
    "    \\begin{equation}\n",
    "    P(x_t=x|x_0,x_1) = \\frac{p(x_1|x_t=x) p(x_t = x|x_0)}{p(x_1|x_0)}\n",
    "    \\end{equation}\n",
    "    \"\"\"\n",
    "    \n",
    "    P_x_to_x1 = conditional_probability(config,x1,x,t=1.,t0=t)\n",
    "    P_x0_to_x = conditional_probability(config,x,x0,t=t,t0=0.)\n",
    "    P_x0_to_x1 = conditional_probability(config,x1,x0,t=1.,t0=0.)\n",
    "\n",
    "    conditional_transition_probability = (P_x_to_x1*P_x0_to_x)/P_x0_to_x1\n",
    "    return conditional_transition_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "dcad8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.softmax(conditional_transition_probability,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e49d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d324240",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    P(x_t=x|x_0,x_1) = \\frac{p(x_1|x_t=x) p(x_t = x|x_0)}{p(x_1|x_0)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0bc751",
   "metadata": {},
   "source": [
    "$\\newcommand{\\*}[1]{\\bar{\\mathbf{#1}}}$\n",
    "\n",
    "\\begin{equation}\n",
    "f_t(\\*x'|\\*x,\\*x_1) = \\frac{p(\\*x_1|x_t=\\*x')}{p(\\*x_1|x_t=\\*x)}f_t(\\*x'|\\*x)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "62c029cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_rate(config,x,t):\n",
    "    right_time_size = lambda t: t if isinstance(t,torch.Tensor) else torch.full((config.batch_size,),t)\n",
    "    t = right_time_size(t).to(x.device)\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    dimension = x.size(1)\n",
    "    \n",
    "    assert batch_size == t.size(0)\n",
    "    \n",
    "    rate_ = torch.full((batch_size,dimension,config.number_of_states),\n",
    "                       config.gamma)                \n",
    "    return rate_\n",
    "\n",
    "def conditional_transition_rate(config,x,x1,t):\n",
    "    \"\"\"\n",
    "    \\begin{equation}\n",
    "    f_t(\\*x'|\\*x,\\*x_1) = \\frac{p(\\*x_1|x_t=\\*x')}{p(\\*x_1|x_t=\\*x)}f_t(\\*x'|\\*x)\n",
    "    \\end{equation}\n",
    "    \"\"\"\n",
    "    where_to_x = torch.arange(0,config.number_of_states)\n",
    "    where_to_x = where_to_x[None,None,:].repeat((config.batch_size,config.number_of_spins,1)).float()\n",
    "    where_to_x = where_to_x.to(x.device)\n",
    "    \n",
    "    P_xp_to_x1 = conditional_probability(config,x1,where_to_x,t=1.,t0=t)\n",
    "    P_x_to_x1 =  conditional_probability(config,x1,x,t=1.,t0=t)\n",
    "    \n",
    "    forward_rate = constant_rate(config,x,t).to(x.device)\n",
    "    \n",
    "    rate_transition = (P_xp_to_x1/P_x_to_x1)*forward_rate\n",
    "    \n",
    "    return rate_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "bf7dd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_pair_x0_x1(batch_1,batch_0):\n",
    "    x_0 = batch_0[0]\n",
    "    x_1 = batch_1[0]\n",
    "    \n",
    "    batch_size_0 = x_0.size(0)\n",
    "    batch_size_1 = x_1.size(0)\n",
    "    \n",
    "    batch_size = min(batch_size_0,batch_size_1)\n",
    "    \n",
    "    x_0 = x_0[:batch_size,:]\n",
    "    x_1 = x_1[:batch_size,:]\n",
    "    \n",
    "    return x_1,x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "a098d5b2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[435], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#sample x from z\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m prob_logits \u001b[38;5;241m=\u001b[39m \u001b[43mconditional_transition_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_to_go\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(prob_logits,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m sampled_x \u001b[38;5;241m=\u001b[39m Categorical(probs)\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "Cell \u001b[1;32mIn[395], line 8\u001b[0m, in \u001b[0;36mconditional_transition_probability\u001b[1;34m(config, x, x1, x0, t)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconditional_transition_probability\u001b[39m(config,x,x1,x0,t):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    \\begin{equation}\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    P(x_t=x|x_0,x_1) = \\frac{p(x_1|x_t=x) p(x_t = x|x_0)}{p(x_1|x_0)}\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    \\end{equation}\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     P_x_to_x1 \u001b[38;5;241m=\u001b[39m \u001b[43mconditional_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mt0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     P_x0_to_x \u001b[38;5;241m=\u001b[39m conditional_probability(config,x,x0,t\u001b[38;5;241m=\u001b[39mt,t0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m)\n\u001b[0;32m     10\u001b[0m     P_x0_to_x1 \u001b[38;5;241m=\u001b[39m conditional_probability(config,x1,x0,t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m,t0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m)\n",
      "Cell \u001b[1;32mIn[394], line 35\u001b[0m, in \u001b[0;36mconditional_probability\u001b[1;34m(config, x, x0, t, t0)\u001b[0m\n\u001b[0;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m right_shape(x)\n\u001b[0;32m     33\u001b[0m x0 \u001b[38;5;241m=\u001b[39m right_shape(x0)\n\u001b[1;32m---> 35\u001b[0m delta_x \u001b[38;5;241m=\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     36\u001b[0m probability \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39mS \u001b[38;5;241m+\u001b[39m w_t0[:,\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m*\u001b[39m( (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39mS) \u001b[38;5;241m+\u001b[39m delta_x )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probability\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "x_to_go = torch.arange(0,config.number_of_states)\n",
    "x_to_go = x_to_go[None,None,:].repeat((config.batch_size,config.number_of_spins,1)).float()\n",
    "x_to_go = x_to_go.to(device)\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = ConditionalBackwardRate(config,device)\n",
    "optimizer = Adam(model.parameters(),lr=config.learning_rate)\n",
    "\n",
    "number_of_training_steps = 0\n",
    "for epoch in range(config.number_of_epochs):\n",
    "    for batch_1, batch_0 in zip(dataloader_1, dataloader_0):\n",
    "        \n",
    "        #data pair and time sample\n",
    "        x_1,x_0 = uniform_pair_x0_x1(batch_1,batch_0)\n",
    "        x_0 = x_0.float().to(device)\n",
    "        x_1 = x_1.float().to(device)\n",
    "        \n",
    "        batch_size = x0.size(0)\n",
    "        time = torch.randn(batch_size).to(device)\n",
    "        \n",
    "        #sample x from z\n",
    "        prob_logits = conditional_transition_probability(config,x_to_go,x_1,x_0,time)\n",
    "        probs = torch.softmax(prob_logits,dim=-1)\n",
    "        sampled_x = Categorical(probs).sample().to(device).float()\n",
    "        \n",
    "        # conditional rate\n",
    "        conditional_rate = conditional_transition_rate(config,sampled_x,x_1,time)\n",
    "        model_rate = model(sampled_x,time)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = (conditional_rate - model_rate).sum(axis=-1).sum(axis=-1)\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        number_of_training_steps += 1\n",
    "        \n",
    "        if number_of_training_steps % 100 == 0:\n",
    "            print(f\"loss {round(loss.item().float(),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "e0897096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 4]), torch.Size([5, 3, 4]))"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_rate.shape,model_rate.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "deefb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalBackwardRate(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,config,device):\n",
    "        super().__init__()\n",
    "        self.expected_data_shape = [config.number_of_spins]\n",
    "        \n",
    "        self.temporal_network = TemporalMLP(dimensions=config.number_of_spins,\n",
    "                                       number_of_states=config.number_of_states,\n",
    "                                       time_embed_dim=config.time_embed_dim,\n",
    "                                       hidden_dim=config.hidden_dim,\n",
    "                                       device=device).to(device)\n",
    "        \n",
    "        #self.logits_to_rates = nn.Linear(self.temporal_network_output_size,)\n",
    "        \n",
    "    def forward(self,x,time):\n",
    "        batch_size = x.size(0)\n",
    "        #================================\n",
    "        #\n",
    "        expected_data_shape_ = torch.Size([batch_size] + self.expected_data_shape)\n",
    "        \n",
    "        temporal_network_logits = self.temporal_network(x,time)\n",
    "        rates_ = softplus(temporal_network_logits)\n",
    "        \n",
    "        return rates_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf5c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b3de9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_bridges.models.temporal_networks.embedding_utils import transformer_timestep_embedding\n",
    "\n",
    "class TemporalMLP(nn.Module):\n",
    "\n",
    "    def __init__(self,dimensions,number_of_states,time_embed_dim,hidden_dim,device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time_embed_dim = time_embed_dim\n",
    "        self.hidden_layer = hidden_dim\n",
    "        self.num_states = number_of_states\n",
    "        self.dimension = dimensions    \n",
    "        self.expected_output_shape = [self.dimension,self.num_states]\n",
    "    \n",
    "        self.define_deep_models()\n",
    "        self.init_weights()\n",
    "        \n",
    "        self.device = device\n",
    "        self.to(self.device)\n",
    "        \n",
    "\n",
    "    def define_deep_models(self):\n",
    "        # layers\n",
    "        self.f1 = nn.Linear(self.dimension, self.hidden_layer)\n",
    "        self.f2 = nn.Linear(self.hidden_layer + self.time_embed_dim, self.dimension * self.num_states)\n",
    "\n",
    "    def forward(self,x,times):\n",
    "        batch_size = x.shape[0]\n",
    "        time_embbedings = transformer_timestep_embedding(times,\n",
    "                                                         embedding_dim=self.time_embed_dim)\n",
    "\n",
    "        step_one = self.f1(x)\n",
    "        step_two = torch.concat([step_one, time_embbedings], dim=1)\n",
    "        rate_logits = self.f2(step_two)\n",
    "        rate_logits = rate_logits.reshape(batch_size,self.dimension,self.num_states)\n",
    "\n",
    "        return rate_logits\n",
    "\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.f1.weight)\n",
    "        nn.init.xavier_uniform_(self.f2.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
