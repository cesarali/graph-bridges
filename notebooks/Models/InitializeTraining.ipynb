{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16b2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4c1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_bridges.models.backward_rates.backward_rate import GaussianTargetRateImageX0PredEMA\n",
    "from graph_bridges.data.dataloaders import DoucetTargetData\n",
    "from graph_bridges.models.samplers.sampling import ReferenceProcess\n",
    "from graph_bridges.models.reference_process.ctdd_reference import ReferenceProcess\n",
    "from graph_bridges.models.losses.ctdd_losses import GenericAux\n",
    "from graph_bridges.models.schedulers.scheduling_ctdd import CTDDScheduler\n",
    "\n",
    "from graph_bridges.models.pipelines.pipelines_utils import create_pipelines\n",
    "from graph_bridges.models.schedulers.scheduling_utils import create_scheduler\n",
    "from graph_bridges.models.backward_rates.backward_rate_utils import create_model\n",
    "from graph_bridges.models.reference_process.reference_process_utils import create_reference\n",
    "from graph_bridges.data.dataloaders_utils import create_dataloader\n",
    "from graph_bridges.models.losses.loss_utils import create_loss\n",
    "\n",
    "from graph_bridges.configs.graphs.lobster.config_base import BridgeConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89d868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BridgeConfig()\n",
    "device = torch.device(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3002aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler\n"
     ]
    }
   ],
   "source": [
    "#=================================================================\n",
    "# CREATE OBJECTS FROM CONFIGURATION\n",
    "\n",
    "data_dataloader: DoucetTargetData\n",
    "model : GaussianTargetRateImageX0PredEMA\n",
    "reference_process: ReferenceProcess\n",
    "loss : GenericAux\n",
    "scheduler:CTDDScheduler\n",
    "\n",
    "data_dataloader = create_dataloader(config,device)\n",
    "model = create_model(config,device)\n",
    "reference_process = create_reference(config,device)\n",
    "loss = create_loss(config,device)\n",
    "scheduler = create_scheduler(config,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c64ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================================\n",
    "sample_ = data_dataloader.sample(config.number_of_paths, device)\n",
    "minibatch = sample_.unsqueeze(1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda3b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIME ===========================================================\n",
    "#ts = torch.rand((minibatch.shape[0],), device=device) * (1.0 - config.loss.min_time) + config.loss.min_time\n",
    "B = minibatch.shape[0]\n",
    "ts = torch.rand((B,), device=device) * (1.0 - config.loss.min_time) + config.loss.min_time\n",
    "#==========\n",
    "\n",
    "x_t, x_tilde, qt0, rate = scheduler.add_noise(minibatch,reference_process,ts,device,return_dict=False)\n",
    "scheduler_noise_output = scheduler.add_noise(minibatch,reference_process,ts,device,return_dict=True)\n",
    "\n",
    "x_logits,p0t_reg,p0t_sig,reg_x = model.forward(minibatch,ts,x_tilde)\n",
    "model_forward_output = model.forward(minibatch,ts,x_tilde,return_dict=True)\n",
    "\n",
    "loss_ = loss.calc_loss(minibatch,x_tilde,qt0,rate,x_logits,reg_x,p0t_sig,p0t_reg,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a23ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d70493b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef06f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8838abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\cesar\\\\Desktop\\\\Projects\\\\DiffusiveGenerativeModelling\\\\Codes\\\\graph-bridges\\\\results\\\\graph\\\\lobster\\\\testing\\\\sinkhorn_{0}.tr'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#config.best_model_path\n",
    "#config.sinkhorn_plot_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bc8f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "num_batches = 20\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.optimizer.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.optimizer.lr_warmup_steps,\n",
    "    num_training_steps=(num_batches * config.optimizer.num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1465558",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = loss.calc_loss(minibatch,x_tilde,qt0,rate,x_logits,reg_x,p0t_sig,p0t_reg,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cf20823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:   0%|                                                                                    | 0/20 [00:11<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 0:   0%|                                                                                    | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'noise_scheduler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m ts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((B,), device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m config\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mmin_time) \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mmin_time\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Sample noise to add to the images\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Add noise to the clean images according to the noise magnitude at each timestep\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# (this is the forward diffusion process)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m \u001b[43mnoise_scheduler\u001b[49m\u001b[38;5;241m.\u001b[39madd_noise(clean_images, noise, timesteps)\n\u001b[0;32m     22\u001b[0m x_t, x_tilde, qt0, rate \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39madd_noise(minibatch,\n\u001b[0;32m     23\u001b[0m                                               reference_process,\n\u001b[0;32m     24\u001b[0m                                               ts,\n\u001b[0;32m     25\u001b[0m                                               device,\n\u001b[0;32m     26\u001b[0m                                               return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#scheduler_noise_output = scheduler.add_noise(minibatch,\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#                                             reference_process,\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#                                             ts,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#loss = F.mse_loss(noise_pred, noise)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#accelerator.backward(loss)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'noise_scheduler' is not defined"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "\n",
    "# Now you train the model\n",
    "for epoch in range(config.optimizer.num_epochs):\n",
    "    progress_bar = tqdm(total=num_batches)\n",
    "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "    for step in range(num_batches):\n",
    "        # Obtain data\n",
    "        sample_ = data_dataloader.sample(config.number_of_paths, device)\n",
    "        minibatch = sample_.unsqueeze(1).unsqueeze(1)\n",
    "        B = minibatch.shape[0]\n",
    "        \n",
    "        # Sample a random timestep for each image\n",
    "        ts = torch.rand((B,), device=device) * (1.0 - config.loss.min_time) + config.loss.min_time\n",
    "        \n",
    "        # Sample noise to add to the images\n",
    "        # Add noise to the clean images according to the noise magnitude at each timestep\n",
    "        # (this is the forward diffusion process)\n",
    "        \n",
    "        #noisy_images = scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "        x_t, x_tilde, qt0, rate = scheduler.add_noise(minibatch,\n",
    "                                                      reference_process,\n",
    "                                                      ts,\n",
    "                                                      device,\n",
    "                                                      return_dict=False)\n",
    "        \n",
    "        #scheduler_noise_output = scheduler.add_noise(minibatch,\n",
    "        #                                             reference_process,\n",
    "        #                                             ts,\n",
    "        #                                             device,\n",
    "        #                                             return_dict=True)\n",
    "        # Predict the noise residual\n",
    "        #noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
    "        #loss = F.mse_loss(noise_pred, noise)\n",
    "        #accelerator.backward(loss)\n",
    "            \n",
    "        x_logits,p0t_reg,p0t_sig,reg_x = model.forward(minibatch,\n",
    "                                                       ts,\n",
    "                                                       x_tilde)\n",
    "            \n",
    "        #model_forward_output = model.forward(minibatch,\n",
    "        #                                     ts,\n",
    "        #                                     x_tilde,\n",
    "        #                                     return_dict=True)\n",
    "            \n",
    "        loss_ = loss.calc_loss(minibatch,\n",
    "                               x_tilde,\n",
    "                               qt0,\n",
    "                               rate,\n",
    "                               x_logits,\n",
    "                               reg_x,\n",
    "                               p0t_sig,\n",
    "                               p0t_reg,\n",
    "                               device)\n",
    "        \n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "        logs = {\"loss\": loss.detach().item(), \n",
    "                \"lr\": lr_scheduler.get_last_lr()[0], \n",
    "                \"step\": global_step}\n",
    "        \n",
    "        progress_bar.set_postfix(**logs)\n",
    "        #accelerator.log(logs, step=global_step)\n",
    "        global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb90bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
